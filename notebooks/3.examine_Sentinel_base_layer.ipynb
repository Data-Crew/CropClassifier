{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook assesses the quality of the Sentinel-2 output by estimating the \n",
    "NDVI (Normalized Difference Vegetation Index) using the red and NIR bands, and \n",
    "verifying the consistency and completeness of the time series data.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Set up imports\n",
    "project_root = os.path.abspath(\"..\") \n",
    "sys.path.append(project_root)  \n",
    "\n",
    "from preprocessing.spark_session import spark  # Reuse the preconfigured SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define NDVI function\n",
    "def ndvi_calc(b04, b08):\n",
    "    if b08 + b04 == 0:\n",
    "        return None\n",
    "    return float((b08 - b04) / (b08 + b04))\n",
    "\n",
    "# Register as a Spark UDF\n",
    "ndvi_udf = udf(ndvi_calc, FloatType())\n",
    "\n",
    "\n",
    "# Helper function to show NDVI for a given location and year\n",
    "def show_ndvi_for_point(df_s2_sampled, lon, lat, cdl, year, ndvi_udf):\n",
    "    df_filtered = df_s2_sampled.where(\n",
    "        (F.col(\"lon\") == lon) &\n",
    "        (F.col(\"lat\") == lat) &\n",
    "        (F.col(\"CDL\") == cdl) &\n",
    "        (F.col(\"year\") == year)\n",
    "    ).withColumn(\"NDVI\", ndvi_udf(F.col(\"red\"), F.col(\"nir\")))\n",
    "\n",
    "    df_filtered.show()\n",
    "    return df_filtered\n",
    "\n",
    "def plot_ndvi_timeseries(df, lon, lat, cdl, year):\n",
    "    # Filter and compute NDVI\n",
    "    df_ndvi = df.where(\n",
    "        (F.col(\"lon\") == lon) &\n",
    "        (F.col(\"lat\") == lat) &\n",
    "        (F.col(\"CDL\") == cdl) &\n",
    "        (F.col(\"year\") == year)\n",
    "    ).withColumn(\"NDVI\", ndvi_udf(F.col(\"red\"), F.col(\"nir\"))) \\\n",
    "     .select(\"scene_date\", \"NDVI\") \\\n",
    "     .orderBy(\"scene_date\")\n",
    "\n",
    "    # Convert to Pandas DataFrame for Plotly\n",
    "    pd_ndvi = df_ndvi.toPandas()\n",
    "    pd_ndvi[\"scene_date\"] = pd.to_datetime(pd_ndvi[\"scene_date\"])\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pd_ndvi[\"scene_date\"],\n",
    "        y=pd_ndvi[\"NDVI\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"NDVI\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"NDVI Time Series ({cdl}, {year})\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"NDVI\",\n",
    "        xaxis=dict(tickformat=\"%Y-%m-%d\"),\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Parquet dataset (adjust the path if needed)\n",
    "df_s2_sampled = spark.read.parquet(\"../data/s2_unique_scene.parquet\")\n",
    "df_s2_sampled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NDVI function to specific points of interest\n",
    "show_ndvi_for_point(df_s2_sampled, -90.5923870410212, 35.57624322094004, \"Cotton\", 2019, ndvi_udf)\n",
    "plot_ndvi_timeseries(df_s2_sampled, -90.5923870410212, 35.57624322094004, \"Cotton\", 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ndvi_for_point(df_s2_sampled, -90.57506989498134, 35.575181872687295, \"Rice\", 2019, ndvi_udf)\n",
    "plot_ndvi_timeseries(df_s2_sampled, -90.57506989498134, 35.575181872687295, \"Rice\", 2019,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ndvi_for_point(df_s2_sampled, -90.55773411916678, 35.57438554009128, \"Dbl Crop WinWht/Soybeans\", 2019, ndvi_udf)\n",
    "plot_ndvi_timeseries(df_s2_sampled, -90.55773411916678, 35.57438554009128, \"Dbl Crop WinWht/Soybeans\", 2019,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ndvi_for_point(df_s2_sampled, -90.57745082006127, 35.56052757960141, \"Soybeans\", 2019, ndvi_udf)\n",
    "plot_ndvi_timeseries(df_s2_sampled, -90.57745082006127, 35.56052757960141, \"Soybeans\", 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ndvi_for_point(df_s2_sampled, -90.58575725883986, 35.57540310857804, \"Corn\", 2019, ndvi_udf)\n",
    "plot_ndvi_timeseries(df_s2_sampled, -90.58575725883986, 35.57540310857804, \"Corn\", 2019)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
