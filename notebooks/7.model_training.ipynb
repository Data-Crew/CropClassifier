{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set up imports\n",
    "project_root = os.path.abspath(\"..\") \n",
    "sys.path.append(project_root)  \n",
    "\n",
    "# Enable efficient use of GPU memory\n",
    "from config.gpu.gpu_utils import configure_tensorflow_gpu\n",
    "configure_tensorflow_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LOAD MODEL ARGUMENTS\n",
    "NUM_FEATURES = 16\n",
    "MAX_EPOCHS = 60\n",
    "ES_PATIENCE = 15\n",
    "DAYS_IN_SERIES = 120\n",
    "DAYS_PER_BUCKET = 5\n",
    "MAX_IMAGES_PER_SERIES = (DAYS_IN_SERIES // DAYS_PER_BUCKET) + 1\n",
    "label_legend = ['Uncultivated', 'Cultivated', 'No Crop Growing', 'Soybeans', 'Rice', 'Corn', 'Cotton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LOAD TRAIN/VAL DATASETS\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "if NUM_FEATURES == 16:\n",
    "    train_ds = tf.data.Dataset.load(\"../data/train_ds_with_idx_16f\")\n",
    "    val_ds = tf.data.Dataset.load(\"../data/val_ds_with_idx_16f\")\n",
    "else:\n",
    "    train_ds = tf.data.Dataset.load(\"../data/train_ds_with_idx_12f\")\n",
    "    val_ds = tf.data.Dataset.load(\"../data/val_ds_with_idx_12f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.  ASSESS DATA QUALITY\n",
    "\n",
    "from models.utils import count_labels\n",
    "\n",
    "train_label_counts = count_labels(train_ds)\n",
    "val_label_counts = count_labels(val_ds)\n",
    "\n",
    "print(\"Train Label Distribution:\")\n",
    "for idx, label in enumerate(label_legend):\n",
    "    print(f\"{label}: {train_label_counts.get(idx, 0)}\")\n",
    "\n",
    "print(\"\\nValidation Label Distribution:\")\n",
    "for idx, label in enumerate(label_legend):\n",
    "    print(f\"{label}: {val_label_counts.get(idx, 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate whether there is an imbalance in the distribution of labels by class\n",
    "from models.utils import evaluate_class_balance\n",
    "evaluate_class_balance(val_label_counts, label_legend, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ARCHITECTURES ASSESSMENT (deeper or compact networks)\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn import baseline_simplecnn\n",
    "\n",
    "model_save_dir = f'../results/models/simplecnn_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_simplecnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_simple, history_simple = baseline_simplecnn(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch', # or 1 by batch\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_simplecnn\",\n",
    "    log_dir=log_dir\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_simplecnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn import baseline_bigcnn\n",
    "\n",
    "model_save_dir = f'../results/models/bigcnn_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_bigcnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_simple, history_simple = baseline_bigcnn(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch', # or 1 by batch\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_bigcnn\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_bigcnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visual Geometry Group (VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vgg import baseline_vgg1d\n",
    "\n",
    "model_save_dir = f'../results/models/vgg1d_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_vgg1d/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_vgg, history_vgg = baseline_vgg1d(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_vgg1d\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_vgg1d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vgg import baseline_vgg1d_compact\n",
    "\n",
    "model_save_dir = f'../results/models/vgg1dcompact_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_vgg1dcompact/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_vggcompact, history_vggcompact = baseline_vgg1d_compact(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_vgg1d_compact\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_vgg1dcompact/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import baseline_unet1d_light\n",
    "\n",
    "model_save_dir = f'../results/models/unet1d_light_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_unet1d_light/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_unet1d_light, history_unet1d_light = baseline_unet1d_light(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_unet1d_light\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_unet1d_light/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import baseline_unet1d  \n",
    "\n",
    "model_save_dir = f'../results/models/unet1d_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_unet1d/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_unet1d, history_unet1d = baseline_unet1d(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_unet1d\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_unet1d/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Residual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import baseline_resnet1d\n",
    "\n",
    "model_save_dir = f'../results/models/resnet1d_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_resnet1d/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_resnet, history_resnet = baseline_resnet1d(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_resnet1d\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_resnet1d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import baseline_resnet1d\n",
    "\n",
    "model_save_dir = f'../results/models/resnet1d_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_resnet1d/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_resunet, history_resunet = baseline_resunet1d(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    use_time_channel=True, # add it to NUM_FEATURES (+ 1)\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_resunet1d\",\n",
    "    log_dir=log_dir\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_resunet1d/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Temporal Convolutional Network (TCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tcn import baseline_tcn\n",
    "\n",
    "model_save_dir = f'../results/models/tcn_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_tcn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_tcn, history_tcn = baseline_tcn(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_tcn\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_tcn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Trasnformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRANSFORMER\n",
    "from models.transformer import baseline_transformer1d\n",
    "\n",
    "model_save_dir = f'../results/models/transformer1d_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_transformer1d/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_transformer, history_transformer = baseline_transformer1d(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_transformer1d\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_transformer1d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN + TRANSFORMER\n",
    "from models.transformer import baseline_cnn_transformer1d\n",
    "\n",
    "model_save_dir = f'../results/models/cnn_transformer1d_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_cnn_transformer1d/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_cnn_transformer, history_cnn_transformer = baseline_cnn_transformer1d(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_cnn_transformer1d\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_cnn_transformer1d/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Efficient Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.efficientnet import baseline_efficientnet1d\n",
    "\n",
    "model_save_dir = f'../results/models/efficientnet1d_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_efficientnet1d/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_efficientnet, history_efficientnet = baseline_efficientnet1d(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_efficientnet1d\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_efficientnet1d/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.inception import baseline_inception1d\n",
    "\n",
    "model_save_dir = f'../results/models/inception1d_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_inception1d/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_inception, history_inception = baseline_inception1d(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_inception1d\",\n",
    "    log_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_inception1d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.inception import baseline_inception1d_se_augmented\n",
    "\n",
    "model_save_dir = f'../results/models/inception1d_se_augmented_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_inception1d_se_augmented/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_inception, history_inception = baseline_inception1d_se_augmented(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_inception1d_se_augmented\",\n",
    "    log_dir=log_dir,\n",
    "    augment=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_inception1d_se_augmented/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.inception import baseline_inception1d_se_mixup_focal_attention_residual\n",
    "\n",
    "model_save_dir = f'../results/models/inception1d_se_mixup_focal_attention_residual_{DAYS_IN_SERIES}days.keras'\n",
    "log_dir = \"../results/logs/fit_inception1d_se_mixup_focal_attention_residual/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model_inception, history_inception = baseline_inception1d_se_mixup_focal_attention_residual(\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    label_legend=label_legend,\n",
    "    max_images_per_series=MAX_IMAGES_PER_SERIES,\n",
    "    num_features=NUM_FEATURES,\n",
    "    xaxis_callback='epoch',\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    es_patience=ES_PATIENCE,\n",
    "    model_save_dir=model_save_dir,\n",
    "    model_name=\"baseline_inception1d_se_mixup_focal_attention_residual\",\n",
    "    log_dir=log_dir,\n",
    "    apply_oversampling=False,\n",
    "    apply_mixup=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=../results/logs/fit_inception1d_se_mixup_focal_attention_residual/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
